# Описание

Обновленная версия решения задачи Credit card fraud detection. Использован датасет по [ссылке](https://www.kaggle.com/datasets/kartik2112/fraud-detection). 

Предобработка датасета заключается в избавлении от неинформативных признаков (ФИО клиента, номер транзакции из цифр и букв и т.д.), иная предобработка не проводилась, поскольку пропуски отсутствуют, а масштабирование данных не нужно из-за специфики моделей - выбраны градиентные бустинги на решающих деревьях, которые инвариантны к масштабу признаков. 

Соотношение меток классов крайне не сбалансировано: примеров положительного класса (мошеннических операций) менее 1%. Для борьбы с дисбалансом используется параметр`scale_pos_weight`в двух моделях, для HistGradientBoostingClassifier, который не имеет этого параметра, использовался тренировочный датасет, предобработанный ADASYN. В качестве эксперимента иные подходы не использовались. 

Наибольший упор был сделан на повышение метрик Precision и Recall для положительного класса, поскольку в данной задаче важно обнаружить как можно больше мошеннических транзакций, но при этом минимизировать количество ложных срабатываний во избежание неудобств пользователей, совершающих легитимные транзакции. 

В ноутбуке сравниваются HistGradientBoostingClassifier, XGBoost, LightGBM как наиболее популярные модели и эффективные на табличных данных. Подбор гиперпараметров проводился с помощью optuna. В основном оптимизировались такие, как `n_estimators`, `learning_rate`, `max_depth`и т.д., точный набор зависит от модели, выбраны были наиболее важные из соображений об ограниченности вычислительных ресурсов.  Лучшая модель сохранена в best_model.pkl.

В будущем при наличии большего объема вычислительных мощностей стоит оптимизировать также параметры subsample, colsample, параметры регуляризации и иные, чтобы избежать переобучения, возможно также сравнить результаты с результатами CNN для этой задачи.
